{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ad5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231eda12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: role='assistant' content='CREATE TABLE employees (id INT PRIMARY KEY, name VARCHAR(255), age INT)' thinking=None images=None tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "model = 'BahaSlama/llama3.1-finetuned:latest' # or huihui_ai/deepseek-r1-abliterated:8b\n",
    "DB = \"SQL\"\n",
    "prompt_engineering = \"You're a Datanase Expert, You will only repond with the actual queries and nothing more. no thinking, no explaining, just the query. Unless asked specifically. Optimize and reduce runtime as much as possible\"\n",
    "input = f\"{prompt_engineering}. Create a {DB} query to make a table called 'employees'\"\n",
    "\n",
    "response = chat(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Response:\", response.message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
