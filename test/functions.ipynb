{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c99512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "920276d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'huihui_ai/deepseek-r1-abliterated:8b'\n",
    "prompt = 'write a long response. this is a test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60e782cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'model': model,\n",
    "    'prompt': prompt,\n",
    "    'stream': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d16756d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streamed_response(payload):\n",
    "    output = requests.post('http://localhost:11434/api/generate', json=payload, stream=True)\n",
    "    for token in output.iter_lines():\n",
    "        token = json.loads(token)\n",
    "        yield token.get('response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23db4337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out how to write a long response based on the user's query. The user wrote, \"Write a long response. This is a test.\" They also mentioned that it's a test, so maybe they're checking if my system can handle longer texts or perhaps they want to assess something else.\n",
      "\n",
      "Hmm, first, I should consider why the user is asking for a long response. It could be part of an evaluation where they need to see if the AI can generate detailed content. Alternatively, it might just be a regular test to check functionality. Either way, my goal is to provide a comprehensive and meaningful response that meets their requirements.\n",
      "\n",
      "I should start by understanding what exactly they're testing. Since it's a test, maybe I need to simulate a scenario or provide information on a topic in depth. But without more context, it's a bit challenging. However, the user did mention it's a test, so perhaps any long-form response would suffice as long as it's well-structured.\n",
      "\n",
      "I should think about the structure of my response. Maybe break it into sections for clarity. Also, I need to ensure that the content is relevant and provides value. Since they didn't specify a particular topic, perhaps a general discussion on a subject like artificial intelligence or a fictional story would be appropriate.\n",
      "\n",
      "Wait, but the user just said \"a test.\" Maybe they don't have a specific purpose beyond testing. So I should focus on making sure my response is as detailed as possible without any errors. It's important to maintain quality even when the request seems vague.\n",
      "\n",
      "I also need to consider the length. How long should a \"long\" response be? A few paragraphs, perhaps around 500-700 words, depending on the context. But since it's a test, I'll aim for substantial depth without unnecessary fluff.\n",
      "\n",
      "Additionally, I should make sure that my response is clear and free of grammatical errors because the user might be assessing both content and writing ability. It's essential to present information logically and coherently.\n",
      "\n",
      "Maybe I can choose a topic that's broad enough to allow detailed expansion but also specific enough to provide meaningful content. For example, discussing the impact of artificial intelligence on modern society could be a good choice as it's widely relevant.\n",
      "\n",
      "I should outline my response: introduction, several body paragraphs each addressing different aspects or impacts, and a conclusion. Each paragraph can delve into specific points, providing evidence or examples where necessary.\n",
      "\n",
      "Wait, but perhaps I'm overcomplicating it. The user might just want a longer version of their initial prompt. So maybe expanding on why they're asking for a test could be beneficial. Alternatively, offering a creative story as part of the response could fulfill the requirement of being long and engaging.\n",
      "\n",
      "Another angle is to consider that the user might be testing the AI's ability to follow instructions accurately. In that case, ensuring that my response is thorough and meets all specified criteria would be crucial. However, since there are no specific instructions beyond \"long,\" I need to create something that's comprehensive on its own.\n",
      "\n",
      "I also wonder if the test is about time constraints or content length. Perhaps they want to see how I handle extended writing sessions without losing focus. In any case, maintaining a coherent and logical flow throughout my response will be key.\n",
      "\n",
      "In summary, I'll craft a detailed response that is both informative and engaging, making sure it's well-structured with clear sections and substantial content. I'll avoid jargon unless necessary and ensure clarity throughout.\n",
      "</think>\n",
      "\n",
      "The task at hand appears to be straightforward: write a long response. However, the mention of \"this is a test\" suggests that there might be underlying requirements or expectations that need to be met. To address this, it would be prudent to consider what exactly is being tested. Is it a test of length, content, creativity, or something else? Without further details, I'll proceed with the assumption that a comprehensive and well-structured response is required.\n",
      "\n",
      "To begin, it's essential to establish a clear purpose for the response. Since the task is labeled as a \"test,\" perhaps the goal is to demonstrate the ability to generate detailed and coherent information on a given topic. If no specific topic is provided, I can choose one of broad interest or relevance, such as the impact of technology on society.\n",
      "\n",
      "Before diving into the content, it's important to outline the structure of the response. A logical flow, supported by evidence or examples, will ensure that the response is both informative and engaging. For instance, if discussing the impact of artificial intelligence on modern society, one might break it down into sections such as technological advancements, societal changes, ethical considerations, and future implications.\n",
      "\n",
      "Each section should delve deeply into its topic, providing sufficient detail to demonstrate an understanding of the subject matter. It's also crucial to maintain clarity and avoid unnecessary complexity, ensuring that each point is clearly articulated.\n",
      "\n",
      "Moreover, the response should reflect a critical thinking process, allowing for nuanced perspectives and balanced viewpoints. This will not only showcase the ability to analyze complex issues but also enhance the overall quality of the response.\n",
      "\n",
      "In summary, the approach involves:\n",
      "1. Identifying the purpose of the test.\n",
      "2. Choosing or refining a topic based on that purpose.\n",
      "3. Structuring the response into clear, well-organized sections.\n",
      "4. Providing detailed and evidence-based content for each section.\n",
      "5. Ensuring clarity, coherence, and logical flow throughout.\n",
      "\n",
      "By following these steps, the resulting response will not only meet the length requirement but also deliver substantial value and insight. It will effectively communicate the thought process and demonstrate a thorough understanding of the topic at hand."
     ]
    }
   ],
   "source": [
    "output = get_streamed_response(payload)\n",
    "\n",
    "for token in output:\n",
    "    print(token, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3dd4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def downloadable_json(raw_data):\n",
    "    data = []\n",
    "    for row in raw_data:\n",
    "        if isinstance(row, tuple):\n",
    "            row = list(row)\n",
    "        data.append(row)\n",
    "    \n",
    "    header = data[0]\n",
    "    rows = data[1:]\n",
    "\n",
    "    json_data = {\n",
    "        \"header\": header,\n",
    "        \"rows\": rows\n",
    "    }\n",
    "\n",
    "    return json_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd71c076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': ['id', 'department', 'salary', 'name'],\n",
       " 'rows': [[2, 'ML', 150000, 'Shruti'],\n",
       "  [3, 'HR', 80000, 'John'],\n",
       "  [4, 'Finance', 90000, 'Emily'],\n",
       "  [5, 'IT', 120000, 'Ravi'],\n",
       "  [6, 'Marketing', 75000, 'Samantha'],\n",
       "  [7, 'Operations', 85000, 'Michael'],\n",
       "  [8, 'Research', 140000, 'Amanda'],\n",
       "  [9, 'Sales', 100000, 'David'],\n",
       "  [10, 'Legal', 65000, 'Olivia'],\n",
       "  [11, 'Product', 110000, 'Kevin'],\n",
       "  [12, 'HR', 50000, 'Alice'],\n",
       "  [13, 'Engineering', 75000, 'Bob'],\n",
       "  [14, 'Marketing', 60000, 'Charlie'],\n",
       "  [15, 'Sales', 80000, 'David'],\n",
       "  [16, 'Finance', 90000, 'Eve'],\n",
       "  [17, 'HR', 5000, 'Alice'],\n",
       "  [18, 'IT', 6000, 'Bob'],\n",
       "  [19, 'Finance', 5500, 'Charlie'],\n",
       "  [20, 'Marketing', 4500, 'David'],\n",
       "  [21, 'Sales', 7000, 'Eve'],\n",
       "  [1, 'IT', 50000, 'John Doe']]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloadable_json([['id', 'department', 'salary', 'name'], (2, 'ML', 150000, 'Shruti'), (3, 'HR', 80000, 'John'), (4, 'Finance', 90000, 'Emily'), (5, 'IT', 120000, 'Ravi'), (6, 'Marketing', 75000, 'Samantha'), (7, 'Operations', 85000, 'Michael'), (8, 'Research', 140000, 'Amanda'), (9, 'Sales', 100000, 'David'), (10, 'Legal', 65000, 'Olivia'), (11, 'Product', 110000, 'Kevin'), (12, 'HR', 50000, 'Alice'), (13, 'Engineering', 75000, 'Bob'), (14, 'Marketing', 60000, 'Charlie'), (15, 'Sales', 80000, 'David'), (16, 'Finance', 90000, 'Eve'), (17, 'HR', 5000, 'Alice'), (18, 'IT', 6000, 'Bob'), (19, 'Finance', 5500, 'Charlie'), (20, 'Marketing', 4500, 'David'), (21, 'Sales', 7000, 'Eve'), (1, 'IT', 50000, 'John Doe')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e4d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def ollama_model_ls():\n",
    "    OLLAMA_BASE = os.getenv('OLLAMA_BASE')\n",
    "    OLLAMA_TAGS = (f'{OLLAMA_BASE}/api/tags')\n",
    "    tag_data = requests.get(OLLAMA_TAGS).json()['models']\n",
    "\n",
    "    models = []\n",
    "    for row in tag_data:\n",
    "        model = {\n",
    "            'model':row.get('model'),\n",
    "            'model_size':row.get('size'),\n",
    "            'paramater_size': row['details'].get('parameter_size')\n",
    "        }\n",
    "        models.append(model)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "df0451fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'qwen3:8b', 'model_size': 5225388164, 'paramater_size': '8.2B'},\n",
       " {'model': 'qwen2.5-coder:1.5b',\n",
       "  'model_size': 986062089,\n",
       "  'paramater_size': '1.5B'},\n",
       " {'model': 'qwen2.5-coder:7b',\n",
       "  'model_size': 4683087561,\n",
       "  'paramater_size': '7.6B'},\n",
       " {'model': 'BahaSlama/llama3.1-finetuned:latest',\n",
       "  'model_size': 4920741072,\n",
       "  'paramater_size': '8.0B'},\n",
       " {'model': 'huihui_ai/deepseek-r1-abliterated:8b',\n",
       "  'model_size': 4920738855,\n",
       "  'paramater_size': '8.0B'}]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_model_ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad141c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ansh\\Documents\\dev\\ScalAble\\src\\config\\settings.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "base_dir = Path('.').resolve().parent\n",
    "p = base_dir / \"src\" / \"config\" / \"settings.json\"\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57742477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\n",
      "    \"model\": \"qwen2.5-coder:1.5b\",\n",
      "\n",
      "    \"prompt\": \"This is a json test, write any thing\",\n",
      "\n",
      "    \"think\": false,\n",
      "\n",
      "    \"keep_alive\": \"5m\",\n",
      "\n",
      "    \"options\": {\n",
      "\n",
      "        \"num_keep\": 5,\n",
      "\n",
      "        \"num_predict\": 100,\n",
      "\n",
      "        \"top_k\": 20,\n",
      "\n",
      "        \"top_p\": 0.9,\n",
      "\n",
      "        \"min_p\":0.0,\n",
      "\n",
      "        \"typical_p\": 0.7,\n",
      "\n",
      "        \"repeat_last_n\": 33,\n",
      "\n",
      "        \"temperature\": 0,\n",
      "\n",
      "        \"repeat_penalty\": 1.2,\n",
      "\n",
      "        \"presence_penalty\":1.5,\n",
      "\n",
      "        \"frequency_penalty\": 1.0,\n",
      "\n",
      "        \"penalize_newline\": false,\n",
      "\n",
      "        \"numa\": false,\n",
      "\n",
      "        \"num_ctx\": 4096,\n",
      "\n",
      "        \"num_batch\": 2,\n",
      "\n",
      "        \"num_gpu\": 1,\n",
      "\n",
      "        \"main_gpu\":0,\n",
      "\n",
      "        \"use_mmap\": true,\n",
      "\n",
      "        \"num_tread\": 8\n",
      "\n",
      "    },\n",
      "\n",
      "    \"stream\": false\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(p, 'r') as file:\n",
    "    for fileline in file:\n",
    "        print(fileline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd16c404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'qwen2.5-coder:1.5b',\n",
       " 'think': False,\n",
       " 'keep_alive': '5m',\n",
       " 'options': {'num_keep': 5,\n",
       "  'num_predict': 100,\n",
       "  'top_k': 20,\n",
       "  'top_p': 0.9,\n",
       "  'min_p': 0.0,\n",
       "  'typical_p': 0.7,\n",
       "  'repeat_last_n': 33,\n",
       "  'temperature': 0,\n",
       "  'repeat_penalty': 1.2,\n",
       "  'presence_penalty': 1.5,\n",
       "  'frequency_penalty': 1.0,\n",
       "  'penalize_newline': False,\n",
       "  'numa': False,\n",
       "  'num_ctx': 4096,\n",
       "  'num_batch': 2,\n",
       "  'num_gpu': 1,\n",
       "  'main_gpu': 0,\n",
       "  'use_mmap': True,\n",
       "  'num_thread': 8},\n",
       " 'stream': False}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SETTINGS_FILE = r\"src\\config\\settings.json\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def SETTINGS_FILE():\n",
    "    curdir = str(Path.cwd().parent.resolve()) + r'\\src\\config\\settings.json'\n",
    "    return curdir\n",
    "\n",
    "def load_settings():\n",
    "    if os.path.exists(SETTINGS_FILE()):\n",
    "        with open(SETTINGS_FILE(), \"r\") as settings:\n",
    "            return json.load(settings)\n",
    "\n",
    "    return {}\n",
    "\n",
    "load_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0299c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
